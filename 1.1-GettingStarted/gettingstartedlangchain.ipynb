{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae95606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f3c76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a95342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47124a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ca146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=llm.invoke(\"What is Agentic AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d6b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems designed to act autonomously with a degree of agency, enabling them to make decisions, take actions, and pursue goals with minimal human intervention. The concept of agency in AI implies that these systems can understand their environment, set objectives, plan actions, and execute them effectively to achieve desired outcomes.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Autonomy**: Agentic AI systems operate independently without continuous human oversight. They can initiate actions based on their programming and perception of their environment.\n",
      "\n",
      "2. **Goal-Oriented Behavior**: These AI systems have specific objectives or goals they aim to achieve. They can prioritize tasks and adjust their strategies to reach these goals efficiently.\n",
      "\n",
      "3. **Perception and Adaptation**: Agentic AI can perceive its environment through sensors or data inputs and adapt its behavior based on changing circumstances or new information.\n",
      "\n",
      "4. **Decision-Making**: They possess the ability to analyze data, evaluate options, and make informed decisions to guide their actions toward achieving goals.\n",
      "\n",
      "5. **Learning and Improvement**: Agentic AI systems often incorporate machine learning techniques, allowing them to learn from experiences and improve their performance over time.\n",
      "\n",
      "### Examples of Agentic AI\n",
      "\n",
      "1. **Autonomous Vehicles**: Self-driving cars like those developed by Tesla or Waymo showcase agentic AI by navigating roads, avoiding obstacles, and making real-time decisions to transport passengers safely.\n",
      "\n",
      "2. **Robotic Process Automation (RPA)**: Advanced robots in manufacturing or logistics that can perform tasks such as assembling products, managing inventory, or handling shipments with minimal human intervention.\n",
      "\n",
      "3. **Personal Assistants**: AI-driven personal assistants (e.g., advanced versions of Siri, Alexa, or Google Assistant) that can manage schedules, control smart home devices, and even initiate actions based on user preferences.\n",
      "\n",
      "4. **Autonomous Drones**: Drones used for delivery, surveillance, or agricultural monitoring that can plan their flight paths, avoid obstacles, and complete missions without direct human control.\n",
      "\n",
      "5. **Intelligent Agents in Software**: AI systems within software applications that can optimize workflows, manage resources, or provide personalized recommendations based on user behavior.\n",
      "\n",
      "### Applications of Agentic AI\n",
      "\n",
      "- **Healthcare**: Autonomous diagnostic systems that analyze medical data, identify patterns, and recommend treatments without constant input from healthcare professionals.\n",
      "  \n",
      "- **Finance**: Algorithmic trading systems that make investment decisions, execute trades, and manage portfolios autonomously based on market conditions.\n",
      "\n",
      "- **Customer Service**: Chatbots and virtual agents that handle customer inquiries, resolve issues, and improve their responses through interactions.\n",
      "\n",
      "- **Smart Cities**: AI systems that manage traffic flow, energy distribution, and public safety measures by making real-time decisions to enhance urban living.\n",
      "\n",
      "### Ethical and Societal Considerations\n",
      "\n",
      "The development and deployment of agentic AI raise several ethical and societal issues:\n",
      "\n",
      "1. **Accountability**: Determining who is responsible for the actions of autonomous AI systems, especially in cases of errors or unintended consequences.\n",
      "\n",
      "2. **Bias and Fairness**: Ensuring that agentic AI systems make decisions free from biases present in their training data or algorithms, which could lead to unfair treatment of individuals or groups.\n",
      "\n",
      "3. **Privacy**: Protecting personal data that agentic AI systems may collect and analyze to make informed decisions.\n",
      "\n",
      "4. **Security**: Safeguarding autonomous AI systems from malicious attacks or manipulations that could lead to harmful actions.\n",
      "\n",
      "5. **Employment Impact**: Addressing the potential displacement of jobs due to automation and finding ways to integrate AI systems into the workforce responsibly.\n",
      "\n",
      "6. **Transparency**: Making the decision-making processes of agentic AI systems understandable to users and stakeholders to build trust and facilitate oversight.\n",
      "\n",
      "### Future Prospects\n",
      "\n",
      "Agentic AI continues to advance with ongoing research in areas like reinforcement learning, natural language processing, and computer vision. As these technologies evolve, agentic AI systems are expected to become more capable, adaptable, and integrated into various aspects of daily life and industry. However, balancing innovation with ethical considerations will be crucial to ensure that the benefits of agentic AI are realized while minimizing potential risks.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Agentic AI represents a significant step towards more autonomous and intelligent systems capable of performing complex tasks with minimal human intervention. By embodying characteristics such as autonomy, goal orientation, and adaptability, agentic AI has the potential to transform numerous industries and aspects of society. However, it also necessitates careful consideration of ethical, legal, and societal implications to ensure its responsible and beneficial deployment.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8357dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user said \"Hi My name is Krish.\" I should respond in a friendly way. Let me start by greeting them back. Maybe say something like, \"Hi Krish! It\\'s nice to meet you.\" Then I can offer assistance by asking how I can help them today. Keep it simple and open-ended so they feel comfortable to ask anything. Let me check if that\\'s appropriate. Yep, that should work. Alright, time to put it all together.\\n\\nWait, maybe add an emoji to make it more welcoming. A smiley face could be good. Hmm, but the user might prefer a more professional tone. Since they introduced themselves, keeping it friendly is probably best. Okay, go with the initial idea.\\n</think>\\n\\nHi Krish! It\\'s nice to meet you! ðŸ˜Š How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 169, 'prompt_tokens': 15, 'total_tokens': 184, 'completion_time': 0.384440055, 'prompt_time': 0.002692405, 'queue_time': 0.078713317, 'total_time': 0.38713246}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_28178d7ff6', 'finish_reason': 'stop', 'logprobs': None}, id='run--d43b8ed3-d57e-491d-bb7a-ec5352c5d71e-0', usage_metadata={'input_tokens': 15, 'output_tokens': 169, 'total_tokens': 184})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "model.invoke(\"Hi My name is Krish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e170b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d414adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000020AF2FBF920>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020AF426B950>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d40b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000020AF2FBF920>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020AF426B950>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chaining\n",
    "chain=prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a293571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I can definitely tell you about Langsmith! \n",
      "\n",
      "Langsmith is an open-source platform designed to simplify the process of building and deploying large language models (LLMs). \n",
      "\n",
      "Here are some key things to know about Langsmith:\n",
      "\n",
      "**What it does:**\n",
      "\n",
      "* **Streamlines LLM development:** It provides a user-friendly interface and tools for tasks like training, evaluating, and fine-tuning LLMs.\n",
      "* **Offers a marketplace:**  Allows developers to share and discover pre-trained models, making it easier to get started or build upon existing work.\n",
      "* **Supports multiple frameworks:**  Works with popular LLM frameworks like Transformers and LlamaIndex, giving users flexibility.\n",
      "* **Facilitates experimentation:**  Its modular design encourages experimentation and rapid prototyping of new LLM applications.\n",
      "\n",
      "**Why it's valuable:**\n",
      "\n",
      "* **Democratizes AI:** Makes LLM development more accessible to a wider range of users, including those without extensive machine learning expertise.\n",
      "* **Accelerates innovation:**  By simplifying the development process, Langsmith empowers developers to focus on building creative and impactful applications.\n",
      "* **Fosters collaboration:**  The marketplace and open-source nature of the platform encourage community sharing and knowledge exchange.\n",
      "\n",
      "**Where to learn more:**\n",
      "\n",
      "* **Official website:** [https://langsmith.ai/](https://langsmith.ai/)\n",
      "* **GitHub repository:** [https://github.com/langsmith-ai/langsmith](https://github.com/langsmith-ai/langsmith)\n",
      "\n",
      "I hope this gives you a good overview of Langsmith! Let me know if you have any other questions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"Can you tell me something about Langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6694a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I can definitely tell you about Langsmith!\n",
      "\n",
      "**Langsmith** is an open-source framework designed specifically for developing and deploying **language model agents**. \n",
      "\n",
      "Think of it as a toolbox built for creating AI assistants that can understand and respond to natural language, perform tasks, and even learn and adapt over time.\n",
      "\n",
      "Here are some key things to know about Langsmith:\n",
      "\n",
      "**What it does:**\n",
      "\n",
      "* **Simplifies Agent Development:** Langsmith provides a structured way to build agents by breaking them down into modular components. This makes it easier to design, test, and iterate on your AI assistants.\n",
      "* **Integrates with Existing Models:** You can leverage powerful pre-trained language models from various sources, like OpenAI's GPT models or HuggingFace, and seamlessly integrate them into your Langsmith agents.\n",
      "* **Supports Local and Cloud Deployment:**  Develop and run your agents locally or deploy them to the cloud for wider accessibility.\n",
      "* **Offers Tools for Evaluation and Monitoring:** Langsmith includes tools to help you assess the performance of your agents and track their behavior over time.\n",
      "\n",
      "**Why it's exciting:**\n",
      "\n",
      "* **Democratizes Agent Building:** By making the process more accessible, Langsmith empowers developers of all levels to create sophisticated AI assistants.\n",
      "* **Promotes Collaboration:** Being open-source, Langsmith fosters a community where developers can share ideas, contribute improvements, and build upon each other's work.\n",
      "* **Opens Doors for Innovation:** The modular and flexible nature of Langsmith encourages experimentation and the creation of novel AI applications.\n",
      "\n",
      "**Where to learn more:**\n",
      "\n",
      "* **Official Website:** [https://github.com/facebookresearch/langs](https://github.com/facebookresearch/langs)\n",
      "* **Documentation:** [https://docs.langs.ai/](https://docs.langs.ai/)\n",
      "\n",
      "Langsmith is definitely a force to be reckoned with in the world of AI development. Its focus on agent building and open-source nature is paving the way for a future where powerful AI assistants are more accessible and widely used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0221a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66da8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fe079e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a5b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform for building and deploying large language models (LLMs) using the LangChain framework.', 'features': ['Simplified LLM development and deployment', 'Integration with various LLMs and tools', 'Modular and extensible design', 'Community-driven development', 'Focus on responsible AI'], 'benefits': ['Faster time to market for LLM applications', 'Increased efficiency and productivity', 'Improved accessibility to LLM technology', 'Enhanced customization and control', 'Promotes ethical and transparent AI development'], 'website': 'https://www.langsmith.com/'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee96082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Assisgnment ---Chatprompttemplate\n",
    "\n",
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed7d7e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Langsmith is an open-source platform designed to simplify the process of building and deploying AI applications, particularly those leveraging large language models (LLMs).', 'key_features': ['**Open-source and accessible:** Langsmith is free to use and modify, allowing developers to tailor it to their specific needs.', '**Streamlined LLM integration:**  It provides easy-to-use tools for connecting with various LLMs, including popular models like GPT-3 and Llama.', '**Model fine-tuning capabilities:** Langsmith enables developers to fine-tune pre-trained LLMs on their own datasets, improving performance for specific tasks.', '**Collaborative development environment:** It fosters collaboration by allowing multiple users to work on the same project simultaneously.', '**User-friendly interface:** The platform offers a web-based interface that simplifies the development workflow.', '**Versatile application building:** Langsmith supports the development of a wide range of AI applications, such as chatbots, text summarizers, and code generators.'], 'benefits': [\"**Reduced development time:** Langsmith's intuitive tools and pre-built components accelerate the development process.\", '**Improved LLM performance:** Fine-tuning capabilities enable developers to optimize LLMs for specific tasks.', '**Cost-effectiveness:**  Being open-source eliminates licensing fees associated with proprietary platforms.', '**Enhanced collaboration:** The collaborative environment facilitates teamwork and knowledge sharing.', '**Greater flexibility and control:** Developers have the freedom to customize and extend Langsmith to meet their unique requirements.'], 'target_audience': ['AI developers and engineers', 'Researchers working with LLMs', 'Data scientists', 'Individuals and businesses interested in building AI applications']}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50822936",
   "metadata": {},
   "source": [
    "### Assigments: https://python.langchain.com/docs/how_to/#prompt-templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c1c1802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca6e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "940f704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```xml\\n<response>\\n  <info>\\n    <name>Langsmith</name>\\n    <description>Langsmith is an open-source platform for developing and deploying large language models (LLMs). It provides a suite of tools and resources to simplify the process of training, fine-tuning, and serving LLMs.</description>\\n    <purpose>Langsmith aims to democratize access to powerful AI technologies by making it easier for developers and researchers to experiment with and build upon existing LLMs.</purpose>\\n    <features>\\n      <item>Modular Design:  Langsmith is built with a modular architecture, allowing users to easily integrate and customize components to suit their specific needs.</item>\\n      <item>Streamlined Workflow: It offers a streamlined workflow for training, fine-tuning, and deploying LLMs, reducing the complexity and time required for development.</item>\\n      <item>Open-Source Community: Langsmith is an open-source project with a vibrant community of contributors, fostering collaboration and innovation.</item>\\n    </features>\\n  </info>\\n</response>\\n``` \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 235, 'prompt_tokens': 195, 'total_tokens': 430, 'completion_time': 0.427272727, 'prompt_time': 0.009483122, 'queue_time': 0.017631112, 'total_time': 0.436755849}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--31f6df6a-6359-4067-9fd5-3d3cb3f5c0c5-0' usage_metadata={'input_tokens': 195, 'output_tokens': 235, 'total_tokens': 430}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1eec50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response><answer>LangChain is an open-source framework designed to simplify the development of applications powered by large language models (LLMs). It provides tools and components for tasks like prompting, chaining, memory management, and agent creation, allowing developers to build more sophisticated and capable LLM applications.</answer></response> \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 39, 'total_tokens': 107, 'completion_time': 0.123636364, 'prompt_time': 0.002697805, 'queue_time': 0.035001481, 'total_time': 0.126334169}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--33a0a956-a4a4-43d9-a906-4cc8c52f802e-0' usage_metadata={'input_tokens': 39, 'output_tokens': 68, 'total_tokens': 107}\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "#from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab7431f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36e1dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why don't scientists trust atoms? Because they make up everything!\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f2ec0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a shortened filmography for Tom Hanks:\n",
      "\n",
      "* <movie>Splash</movie>\n",
      "* <movie>Big</movie>\n",
      "* <movie>Philadelphia</movie>\n",
      "* <movie>Forrest Gump</movie>\n",
      "* <movie>Saving Private Ryan</movie>\n",
      "* <movie>Cast Away</movie>\n",
      "* <movie>The Da Vinci Code</movie>\n",
      "* <movie>Toy Story</movie> (voice)\n",
      "* <movie>Apollo 13</movie>\n",
      "* <movie>Bridge of Spies</movie>\n",
      "\n",
      "\n",
      "\n",
      "This list includes some of his most iconic and critically acclaimed roles. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c90caccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfed2d4",
   "metadata": {},
   "source": [
    "### Assisgment:\n",
    "Create a simple assistant that uses any LLM and should be pydantic, when we ask about any product it should give you two information product Name, product details tentative price in USD (integer). use chat Prompt Template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2999f98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
